{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['“Specifically, it intends to focus on services incorporating cutting-edge technology, including AI and IoT.” Beyond the hype they share, combining IoT and AI can make a lot of sense.', 'In Japan, the AI/IoT combination is so hot that Japanese tech giant Fujitsu is reportedly dumping its mobile phone business (and mobile is probably the moment’s third-hottest trend) to focus on the intersection of AI and IoT.', 'The goal, per the company’s Watson IoT website, is to marry cognitive computing (the Watson AI platform) to vast arrays of IoT sensors.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "class FrequencySummarizer:\n",
    "    def __init__(self, min_cut=0.1, max_cut=0.9):\n",
    "        self._min_cut = min_cut\n",
    "        self._max_cut = max_cut \n",
    "        self._stopwords = set(stopwords.words('english') + list(punctuation))\n",
    "\n",
    "    # _compute_frequencies - takes in a list of sentences, and outputs a dictionary,\n",
    "    # where the keys are words, and values are the frequencies of those words in the \n",
    "    # set of sentences\n",
    "    def _compute_frequencies(self, word_sent):\n",
    "        freq = defaultdict(int)\n",
    "        \n",
    "        # count non stopwords\n",
    "        for s in word_sent:\n",
    "            for word in s:\n",
    "                if word not in self._stopwords:\n",
    "                    freq[word] += 1\n",
    "\n",
    "        # calculate frequency from count\n",
    "        m = float(max(freq.values()))\n",
    "        for w in list(freq.keys()):\n",
    "            freq[w] = freq[w]/m\n",
    "            if freq[w] >= self._max_cut or freq[w] <= self._min_cut:\n",
    "                del freq[w]\n",
    "\n",
    "        return freq\n",
    "\n",
    "    def summarize(self, text, n):\n",
    "        sentences = sent_tokenize(text)\n",
    "        assert n <= len(sentences)\n",
    "\n",
    "        words_in_sentences = [word_tokenize(s.lower()) for s in sentences]\n",
    "        \n",
    "        self._freq = self._compute_frequencies(words_in_sentences)\n",
    "\n",
    "        ranking = defaultdict(int)\n",
    "\n",
    "        for i,sentence in enumerate(words_in_sentences):\n",
    "            for w in sentence:\n",
    "                if w in self._freq:\n",
    "                    ranking[i] += self._freq[w]\n",
    "\n",
    "        sentence_indexes = nlargest(n, ranking, key=ranking.get)\n",
    "        return [sentences[j] for j in sentence_indexes]\n",
    "\n",
    "def get_text_from_paragraphs(article):\n",
    "    return ' '.join(map(lambda p: p.text, article.find_all('p')))\n",
    "\n",
    "def get_only_text_washington_post_url(url):\n",
    "\n",
    "    page = urllib.request.urlopen(url).read().decode('utf8')\n",
    "\n",
    "    soup = BeautifulSoup(page, \"html5lib\")\n",
    "\n",
    "#    text = ' '.join(map(get_text_from_paragraphs, soup.find_all('article')))\n",
    "    text = ' '.join(map(get_text_from_paragraphs, soup.find_all(attrs={\"itemprop\": \"articleBody\"})))\n",
    "\n",
    "    return soup.title.text, text\n",
    "\n",
    "someUrl = \"https://www.networkworld.com/article/3220437/internet-of-things/ai-and-iot-like-peanut-butter-and-chocolate.html\"\n",
    "\n",
    "textOfUrl = get_only_text_washington_post_url(someUrl)\n",
    "fs = FrequencySummarizer()\n",
    "\n",
    "summary = fs.summarize(textOfUrl[1], 3)\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
